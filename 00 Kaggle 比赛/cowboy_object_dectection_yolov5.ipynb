{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®ç¯å¢ƒå’Œä¸‹è½½ YOLOv5\n",
    "import torch\n",
    "import torchvision\n",
    "import wandb\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import yaml\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "# æŸ¥çœ‹ torch ç‰ˆæœ¬å’Œ GPU å¯ç”¨æ€§\n",
    "# print(f\"Setup complete. Usidu -sh /tmp/ng torch {torch.__version__}, torchvision {torchvision.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½® tensorborad å¯è§†åŒ–å¹³å°ï¼ˆå¯é€‰ï¼‰\n",
    "# load_ext tensorboard\n",
    "# è¯»å–ç›®å½•ä¸­çš„æ—¥å¿—æ–‡ä»¶ï¼Œç”¨äºå¯è§†åŒ–\n",
    "# tensorboard --logdir /kaggle/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½® W&B å¯è§†åŒ–å¹³å°\n",
    "# ç”¨æ¥æœºå™¨å­¦ä¹ è·Ÿè¸ªå’Œå¯è§†åŒ–çš„å·¥å…·ï¼Œå¯ä»¥è®°å½•å’Œå¯è§†åŒ–æ¨¡å‹è®­ç»ƒä¸­çš„æŒ‡æ ‡å’Œè¶…å‚æ•°ï¼Œæ¨¡å‹ç»“æ„ç­‰ä¿¡æ¯\n",
    "# pip install -q --upgrade wandb  \n",
    "# wandb.login()  # ç™»å½•è®¤è¯ï¼Œè¿”å›è®¿é—®ä»¤ç‰Œï¼Œå°†å…¶ä¿å­˜åœ¨æœ¬åœ°ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨æ— éœ€é‡å¤ç™»å½•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.å°†æ ‡æ³¨æ¡† bounding box ä» COCO æ•°æ®é›†æ ¼å¼è½¬æ¢ä¸º YOLO æ•°æ®é›†æ ¼å¼\n",
    "# åŠ è½½ COCO æ ¼å¼æ ‡æ³¨çš„ JSON æ–‡ä»¶\n",
    "json_file_path = '/root/autodl-tmp/data/cowboyoutfits/train.json'\n",
    "\n",
    "data = json.load(open(json_file_path, 'r'))\n",
    "\n",
    "# åˆ›å»ºç›®å½•ï¼Œç”¨äºä¿å­˜ YOLO æ ¼å¼çš„æ ‡æ³¨\n",
    "yolo_anno_path = '/root/autodl-tmp/kaggle/training/yolo_anno/'\n",
    "\n",
    "if not os.path.exists(yolo_anno_path):\n",
    "    os.makedirs(yolo_anno_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å› ä¸ºæˆ‘ä»¬çš„ annotation label æ˜¯ä¸è¿ç»­ï¼Œä¼šå¯¼è‡´åé¢æŠ¥é”™ï¼Œæ‰€ä»¥è¿™é‡Œç”Ÿæˆ map æ˜ å°„\n",
    "# å°† COCO æ ‡æ³¨æ•°æ®ä¸­çš„ç±»åˆ«IDæ˜ å°„ä¸ºè¿ç»­çš„æ•´æ•°ï¼Œä»¥è§£å†³ç±»åˆ«IDä¸è¿ç»­å¯¼è‡´åç»­æŠ¥é”™é—®é¢˜\n",
    "cate_id_map = {}\n",
    "num = 0\n",
    "for cate in data['categories']:\n",
    "    cate_id_map[cate['id']] = num\n",
    "    num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{87: 0, 1034: 1, 131: 2, 318: 3, 588: 4}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 87, 'name': 'belt', 'freebase_id': '/m/0176mf'},\n",
       " {'id': 1034, 'name': 'sunglasses', 'freebase_id': '/m/017ftj'},\n",
       " {'id': 131, 'name': 'boot', 'freebase_id': '/m/01b638'},\n",
       " {'id': 318, 'name': 'cowboy_hat', 'freebase_id': '/m/025rp__'},\n",
       " {'id': 588, 'name': 'jacket', 'freebase_id': '/m/032b3c'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¯¹æ¯”\n",
    "data['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”¨äºå°†è¾¹ç•Œæ¡† bounding box ä» COCO è½¬æ¢ä¸º YOLO æ ¼å¼\n",
    "def cc2yolo_bbox(img_width, img_height, bbox):\n",
    "    dw = 1. / img_width\n",
    "    dh = 1. / img_height\n",
    "    x = bbox[0] + bbox[2] / 2.0\n",
    "    y = bbox[1] + bbox[3] / 2.0\n",
    "    w = bbox[2]\n",
    "    h = bbox[3]\n",
    " \n",
    "    x = x * dw\n",
    "    w = w * dw\n",
    "    y = y * dh\n",
    "    h = h * dh\n",
    "    return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3062/3062 [00:02<00:00, 1354.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºæ–‡ä»¶ç”¨äºè®­ç»ƒæ•°æ®é›†çš„ä¿¡æ¯\n",
    "# å°†COCOæ ¼å¼çš„æ ‡æ³¨ï¼ˆbound boxï¼‰è½¬æ¢ä¸ºYOLOæ ¼å¼ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªè®­ç»ƒæ•°æ®é›†çš„CSVæ–‡ä»¶\n",
    "f = open('/root/autodl-tmp/kaggle/training/train.csv','w')\n",
    "# å†™å…¶æ–‡ä»¶çš„è¡¨å¤´ idï¼Œfile_name\n",
    "f.write('id,file_name\\n')\n",
    "\n",
    "# å¯¹ COCO æ•°æ®é›†ä¸­çš„æ¯ä¸ªå›¾åƒè¿›è¡Œéå†\n",
    "for i in tqdm(range(len(data['images']))):\n",
    "    filename = data['images'][i]['file_name']   # å›¾åƒæ–‡ä»¶å\n",
    "    img_width = data['images'][i]['width']      # å›¾åƒå®½åº¦\n",
    "    img_height = data['images'][i]['height']\n",
    "    img_id = data['images'][i]['id']\n",
    "    yolo_txt_name = filename.split('.')[0] + '.txt' # ç”ŸæˆYOLOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶åï¼Œå°†æ–‡ä»¶åç¼€æ”¹æˆ\".txt\"\n",
    "    \n",
    "    # å°†å½“å‰å›¾åƒçš„IDå’Œæ–‡ä»¶åå†™åˆ° CSV æ–‡ä»¶\n",
    "    f.write('{},{}\\n'.format(img_id, filename)) \n",
    "\n",
    "    # åˆ›å»ºç”¨äºå†™åˆ°YOLOæ ¼å¼æ ‡æ³¨çš„æ–‡æœ¬\n",
    "    yolo_txt_file = open(os.path.join(yolo_anno_path, yolo_txt_name), 'w')\n",
    "    \n",
    "    # éå†COCOæ•°æ®é›†ä¸­çš„æ¯ä¸ªæ ‡æ³¨\n",
    "    for anno in data['annotations']:\n",
    "        # åˆ¤æ–­å½“å‰æ ‡æ³¨æ˜¯å¦ä¸å›¾åƒåŒ¹é…\n",
    "        if anno['image_id'] == img_id:\n",
    "            # è°ƒç”¨å‡½æ•°ï¼Œå°† COCO æ ¼å¼çš„è¾¹ç•Œæ¡†è½¬æ¢ä¸º YOLO æ ¼å¼\n",
    "            yolo_bbox = cc2yolo_bbox(img_width, img_height, anno['bbox']) # \"bbox\": [x,y,width,height]      \n",
    "            # å°† YOLO æ ¼å¼çš„æ ‡æ³¨å†™åˆ° YOLO æ ¼å¼æ ‡æ³¨æ–‡ä»¶  \n",
    "            yolo_txt_file.write('{} {} {} {} {}\\n'.format(cate_id_map[anno['category_id']], yolo_bbox[0], yolo_bbox[1], yolo_bbox[2], yolo_bbox[3]))\n",
    "    yolo_txt_file.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9860841628484337660</td>\n",
       "      <td>88d8bf3754317ffc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15984033263460081658</td>\n",
       "      <td>ddd2b190ea90dffa.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76077631043502082</td>\n",
       "      <td>010e4833cdb38002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18065680256228130812</td>\n",
       "      <td>fab6307a1a43fffc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9491379842992996352</td>\n",
       "      <td>83b827ae01e68000.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id             file_name\n",
       "0   9860841628484337660  88d8bf3754317ffc.jpg\n",
       "1  15984033263460081658  ddd2b190ea90dffa.jpg\n",
       "2     76077631043502082  010e4833cdb38002.jpg\n",
       "3  18065680256228130812  fab6307a1a43fffc.jpg\n",
       "4   9491379842992996352  83b827ae01e68000.jpg"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æŸ¥çœ‹åˆšç”Ÿæˆçš„è®­ç»ƒé›†\n",
    "train = pd.read_csv('/root/autodl-tmp/kaggle/training/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of total training images: 3062, training images: 2755. validation images: 307\n"
     ]
    }
   ],
   "source": [
    "# 4.å°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "# å°†è®­ç»ƒæ•°æ®éšæœºåˆ†æˆä¸¤éƒ¨åˆ†:è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œé€šè¿‡å›ºå®šéšæœºç§å­ random=233 è¿›è¡Œåˆ’åˆ†ï¼Œ10%åšéªŒè¯é›†\n",
    "train_df, valid_df = train_test_split(train, test_size=0.10, random_state=233)\n",
    "print(f'Size of total training images: {len(train)}, training images: {len(train_df)}. validation images: {len(valid_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>6313228391827179284</td>\n",
       "      <td>579d17c600c50714.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>10846323739029586428</td>\n",
       "      <td>9685e1f96fbec1fc.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>13386314881303920819</td>\n",
       "      <td>b9c5be75f7a540b3.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>6443506009312068821</td>\n",
       "      <td>596bee93892404d5.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>11513085654045198804</td>\n",
       "      <td>9fc6b267460289d4.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>2104996849403692053</td>\n",
       "      <td>1d36737b56060415.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>1494888502052588152</td>\n",
       "      <td>14bee92c1fa90a78.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>1932289094778455674</td>\n",
       "      <td>1ad0deb1a9a1867a.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>12096828553779053656</td>\n",
       "      <td>a7e0917a58cd8458.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>2155400085207516008</td>\n",
       "      <td>1de984f52ba40368.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id             file_name  split\n",
       "1908   6313228391827179284  579d17c600c50714.jpg  train\n",
       "1636  10846323739029586428  9685e1f96fbec1fc.jpg  train\n",
       "361   13386314881303920819  b9c5be75f7a540b3.jpg  train\n",
       "2186   6443506009312068821  596bee93892404d5.jpg  train\n",
       "1393  11513085654045198804  9fc6b267460289d4.jpg  train\n",
       "1314   2104996849403692053  1d36737b56060415.jpg  train\n",
       "753    1494888502052588152  14bee92c1fa90a78.jpg  train\n",
       "1412   1932289094778455674  1ad0deb1a9a1867a.jpg  train\n",
       "767   12096828553779053656  a7e0917a58cd8458.jpg  train\n",
       "634    2155400085207516008  1de984f52ba40368.jpg  train"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ç”¨äºç”Ÿæˆæ–°çš„æ•°æ®é›†å¹¶æ·»åŠ  split åˆ—ï¼Œç”¨äºæ ‡è®°æ¯ä¸ªæ ·æœ¬å±äºè®­ç»ƒé›†è¿˜æ˜¯éªŒè¯é›†ï¼Œé€šè¿‡å°†è®­ç»ƒé›†å’ŒéªŒè¯é›†åˆå¹¶ç”Ÿæˆæ–°çš„æ•°æ®é›† df\n",
    "train_df.loc[:, 'split'] = 'train'\n",
    "valid_df.loc[:, 'split'] = 'valid'\n",
    "df = pd.concat([train_df, valid_df]).reset_index(drop=True)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸ºè¿›è¡Œ YOLO è‡ªå®šä¹‰è®­ç»ƒï¼Œå‡†å¤‡ç‰¹å®šçš„æ–‡ä»¶å¤¹ç»“æ„\n",
    "os.makedirs('../kaggle/training/cowboy/images/train', exist_ok=True)\n",
    "os.makedirs('../kaggle/training/cowboy/images/valid', exist_ok=True)\n",
    "\n",
    "os.makedirs('../kaggle/training/cowboy/labels/train', exist_ok=True)\n",
    "os.makedirs('../kaggle/training/cowboy/labels/valid', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3062/3062 [00:02<00:00, 1376.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# å°†å›¾åƒå’Œæ ‡æ³¨ç§»åŠ¨åˆ°ç›¸å…³çš„æ‹†åˆ†æ–‡ä»¶ è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = df.loc[i]\n",
    "    name = row.file_name.split('.')[0] # æå‡º file_name \n",
    "    if row.split == 'train':\n",
    "        copyfile(f'/root/autodl-tmp/data/cowboyoutfits/images/{name}.jpg', f'/root/autodl-tmp/kaggle/training/cowboy/images/train/{name}.jpg')\n",
    "        copyfile(f'/root/autodl-tmp/kaggle/training/yolo_anno/{name}.txt', f'/root/autodl-tmp/kaggle/training/cowboy/labels/train/{name}.txt')\n",
    "    else:\n",
    "        copyfile(f'/root/autodl-tmp/data/cowboyoutfits/images/{name}.jpg', f'/root/autodl-tmp/kaggle/training/cowboy/images/valid/{name}.jpg')\n",
    "        copyfile(f'/root/autodl-tmp/kaggle/training/yolo_anno/{name}.txt', f'/root/autodl-tmp/kaggle/training/cowboy/labels/valid/{name}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶\n",
    "# æ•°æ®é›†é…ç½®ä¿¡æ¯ï¼Œè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„è·¯å¾„ï¼Œç±»åˆ«æ•°é‡å’Œç±»åˆ«åç§°\n",
    "\n",
    "\n",
    "data_yaml = dict(\n",
    "    train = '/root/autodl-tmp/kaggle/training/cowboy/images/train/',\n",
    "    val = '/root/autodl-tmp/kaggle/training/cowboy/images/valid/',\n",
    "    nc = 5,  # è¦æ£€æµ‹çš„ç±»åˆ«æ•°é‡ä¸º5\n",
    "    names = ['belt', 'sunglasses', 'boot', 'cowboy_hat', 'jacket'] # ç±»åˆ«åç§°çš„åˆ—è¡¨\n",
    ")\n",
    "\n",
    "# we will make the file under the yolov5/data/ directory\n",
    "with open('/root/autodl-tmp/kaggle//training/yolov5/data/data.yaml', 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¶…å‚æ•°\n",
    "# Hyperparameters for COCO training from scratch\n",
    "# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n",
    "# æ°´å¹³æœ‰é™ï¼Œéƒ½æ˜¯é»˜è®¤å€¼\n",
    "\n",
    "\n",
    "lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
    "lrf: 0.2  # final OneCycleLR learning rate (lr0 * lrf)\n",
    "momentum: 0.937  # SGD momentum/Adam beta1\n",
    "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
    "warmup_epochs: 3.0  # warmup epochs (fractions ok)\n",
    "warmup_momentum: 0.8  # warmup initial momentum\n",
    "warmup_bias_lr: 0.1  # warmup initial bias lr\n",
    "box: 0.05  # box loss gain\n",
    "cls: 0.5  # cls loss gain\n",
    "cls_pw: 1.0  # cls BCELoss positive_weight\n",
    "obj: 1.0  # obj loss gain (scale with pixels)\n",
    "obj_pw: 1.0  # obj BCELoss positive_weight\n",
    "iou_t: 0.20  # IoU training threshold\n",
    "anchor_t: 4.0  # anchor-multiple threshold\n",
    "# anchors: 3  # anchors per output layer (0 to ignore)\n",
    "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
    "hsv_h: 0.015  # image HSV-Hue augmentation (fraction\n",
    "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
    "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n",
    "degrees: 0.0  # image rotation (+/- deg)\n",
    "translate: 0.1  # image translation (+/- fraction)\n",
    "scale: 0.5  # image scale (+/- gain)\n",
    "shear: 0.0  # image shear (+/- deg)\n",
    "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
    "flipud: 0.0  # image flip up-down (probability)\n",
    "fliplr: 0.5  # image flip left-right (probability)\n",
    "mosaic: 1.0  # image mosaic (probability)\n",
    "mixup: 0.0  # image mixup (probability)\n",
    "copy_paste: 0.0  # segment copy-paste (probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®è®­ç»ƒå‚æ•°å’Œæ¨¡å‹åç§°çš„å˜é‡\n",
    "\n",
    "BATCH_SIZE = 32     # æ‰¹é‡å¤§å°ï¼Œç”¨äºæŒ‡å®šæ¯æ¬¡è®­ç»ƒæ—¶ä½¿ç”¨çš„æ ·æœ¬æ•° \n",
    "EPOCHS = 5          # è®­ç»ƒçš„è½®æ•°ï¼Œæ•´ä¸ªæ•°æ®é›†è¢«æ¨¡å‹å¤„ç†çš„æ¬¡æ•°ï¼Œæ¯ä¸ª epoch éƒ½åŒ…å«è®­ç»ƒå’ŒéªŒè¯è¿‡ç¨‹\n",
    "MODEL = 'yolov5m.pt'  # æ¨¡å‹çš„åç§°ï¼Œå³ YOLOv5 é¢„è®­ç»ƒæƒé‡æ–‡ä»¶\n",
    "name = f'{MODEL}_BS_{BATCH_SIZE}_EP_{EPOCHS}'   # ç”¨äºç”Ÿæˆè®­ç»ƒçš„æ ‡è¯†åç§°ï¼Œå³æ¨¡å‹åç§°ï¼Œæ‰¹é‡å¤§å°ï¼Œè½®æ•°ä¿¡æ¯\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/kaggle/training/yolov5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mboke\u001b[0m (\u001b[33mcompetition_ml\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=images, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/root/autodl-tmp/kaggle/working/kaggle-cowboy, name=yolov5m.pt_BS_32_EP_5, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
      "YOLOv5 ğŸš€ v7.0-203-g0897415 Python-3.10.8 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /root/autodl-tmp/kaggle/working/kaggle-cowboy', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/autodl-tmp/kaggle/training/yolov5/wandb/run-20230804_154511-yahcdzkf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5m.pt_BS_32_EP_5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/competition_ml/kaggle-cowboy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/competition_ml/kaggle-cowboy/runs/yahcdzkf\u001b[0m\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     40410  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20887482 parameters, 20887482 gradients, 48.3 GFLOPs\n",
      "\n",
      "Transferred 475/481 items from yolov5m.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /root/autodl-tmp/kaggle/training/cowboy/labels/train.cache... 27\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.3GB images): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2755/2755 [00:04<00:00, 6\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /root/autodl-tmp/kaggle/training/cowboy/labels/valid.cache... 307 \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB images): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [00:01<00:00, 216.3\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.32 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
      "Plotting labels to /root/autodl-tmp/kaggle/working/kaggle-cowboy/yolov5m.pt_BS_32_EP_5/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/root/autodl-tmp/kaggle/working/kaggle-cowboy/yolov5m.pt_BS_32_EP_5\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.67G      0.083    0.03384    0.03257         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        307        600      0.541      0.274      0.156     0.0563\n",
      "Saving model artifact on epoch 1\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      10.4G    0.06033    0.02668    0.01118         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        307        600      0.558      0.424      0.348      0.144\n",
      "Saving model artifact on epoch 2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      4.42G    0.05442     0.0238   0.007145          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        307        600      0.546      0.429      0.354       0.14\n",
      "Saving model artifact on epoch 3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      10.4G    0.04554    0.02243   0.005028         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        307        600      0.748      0.515      0.517      0.261\n",
      "Saving model artifact on epoch 4\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      10.4G    0.04249    0.02196   0.003818         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        307        600      0.727      0.526      0.528      0.277\n",
      "\n",
      "5 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from /root/autodl-tmp/kaggle/working/kaggle-cowboy/yolov5m.pt_BS_32_EP_5/weights/last.pt, 42.2MB\n",
      "Optimizer stripped from /root/autodl-tmp/kaggle/working/kaggle-cowboy/yolov5m.pt_BS_32_EP_5/weights/best.pt, 42.2MB\n",
      "\n",
      "Validating /root/autodl-tmp/kaggle/working/kaggle-cowboy/yolov5m.pt_BS_32_EP_5/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20869098 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        307        600      0.727      0.527      0.528      0.277\n",
      "                  belt        307          1          1          0    0.00137   0.000412\n",
      "            sunglasses        307        268       0.73      0.698      0.705      0.341\n",
      "                  boot        307         56      0.614       0.37      0.427      0.227\n",
      "            cowboy_hat        307         44      0.558      0.818       0.75      0.349\n",
      "                jacket        307        231      0.736      0.749      0.757      0.468\n",
      "Results saved to \u001b[1m/root/autodl-tmp/kaggle/working/kaggle-cowboy/yolov5m.pt_BS_32_EP_5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 â–â–…â–…â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 â–â–„â–„â–‡â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision â–â–‚â–â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall â–â–…â–…â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss â–ˆâ–„â–ƒâ–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss â–ˆâ–ƒâ–‚â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss â–ˆâ–„â–‚â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss â–ˆâ–…â–„â–‚â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss â–ˆâ–ƒâ–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss â–ˆâ–ƒâ–ƒâ–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 â–ˆâ–…â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 â–â–†â–ˆâ–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 â–â–†â–ˆâ–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.52806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.27731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.72654\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.52579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.52812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.27688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.72748\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.00382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33myolov5m.pt_BS_32_EP_5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/competition_ml/kaggle-cowboy/runs/yahcdzkf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ï¸âš¡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/competition_ml/kaggle-cowboy/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjg3ODQ2MjY2/version_details/v0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 17 media file(s), 7 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230804_154511-yahcdzkf/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n"
     ]
    }
   ],
   "source": [
    "# 8.è®­ç»ƒ\n",
    "# åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯è§†åŒ–å…¶è¿‡ç¨‹ \n",
    "# å…ˆåˆ° yolov5 æ–‡ä»¶å¤¹ä¸­\n",
    "%cd /root/autodl-tmp/kaggle/training/yolov5\n",
    "\n",
    "# è®­ç»ƒè„šæœ¬\n",
    "!python train.py --batch {BATCH_SIZE} \\\n",
    "                 --epochs {EPOCHS} \\\n",
    "                 --data data.yaml \\\n",
    "                 --weights {MODEL} \\\n",
    "                 --save-period 1 \\\n",
    "                 --project /root/autodl-tmp/kaggle/working/kaggle-cowboy \\\n",
    "                 --name {name} \\\n",
    "                 --cache images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ W&B åœ¨çº¿å±•ç¤ºè®­ç»ƒç»“æœï¼Œå¹¶åœ¨æœ¬åœ°è¿›è¡Œå¯è§†åŒ–\n",
    "# å°†è®­ç»ƒç»“æœå‹ç¼©æˆZIPï¼Œä¾¿äºå¯è§†åŒ–\n",
    "# zip -r /root/autodl-tmp/kaggle/working/output.zip /root/autodl-tmp/kaggle/working/kaggle-cowboy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
