{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置环境和下载 YOLOv5\n",
    "import torch\n",
    "import torchvision\n",
    "import wandb\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import yaml\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "# 查看 torch 版本和 GPU 可用性\n",
    "# print(f\"Setup complete. Usidu -sh /tmp/ng torch {torch.__version__}, torchvision {torchvision.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置 tensorborad 可视化平台（可选）\n",
    "# load_ext tensorboard\n",
    "# 读取目录中的日志文件，用于可视化\n",
    "# tensorboard --logdir /kaggle/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置 W&B 可视化平台\n",
    "# 用来机器学习跟踪和可视化的工具，可以记录和可视化模型训练中的指标和超参数，模型结构等信息\n",
    "# pip install -q --upgrade wandb  \n",
    "# wandb.login()  # 登录认证，返回访问令牌，将其保存在本地，以便后续使用无需重复登录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.将标注框 bounding box 从 COCO 数据集格式转换为 YOLO 数据集格式\n",
    "# 加载 COCO 格式标注的 JSON 文件\n",
    "json_file_path = '/root/autodl-tmp/data/cowboyoutfits/train.json'\n",
    "\n",
    "data = json.load(open(json_file_path, 'r'))\n",
    "\n",
    "# 创建目录，用于保存 YOLO 格式的标注\n",
    "yolo_anno_path = '/root/autodl-tmp/kaggle/training/yolo_anno/'\n",
    "\n",
    "if not os.path.exists(yolo_anno_path):\n",
    "    os.makedirs(yolo_anno_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为我们的 annotation label 是不连续，会导致后面报错，所以这里生成 map 映射\n",
    "# 将 COCO 标注数据中的类别ID映射为连续的整数，以解决类别ID不连续导致后续报错问题\n",
    "cate_id_map = {}\n",
    "num = 0\n",
    "for cate in data['categories']:\n",
    "    cate_id_map[cate['id']] = num\n",
    "    num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{87: 0, 1034: 1, 131: 2, 318: 3, 588: 4}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 87, 'name': 'belt', 'freebase_id': '/m/0176mf'},\n",
       " {'id': 1034, 'name': 'sunglasses', 'freebase_id': '/m/017ftj'},\n",
       " {'id': 131, 'name': 'boot', 'freebase_id': '/m/01b638'},\n",
       " {'id': 318, 'name': 'cowboy_hat', 'freebase_id': '/m/025rp__'},\n",
       " {'id': 588, 'name': 'jacket', 'freebase_id': '/m/032b3c'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对比\n",
    "data['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于将边界框 bounding box 从 COCO 转换为 YOLO 格式\n",
    "def cc2yolo_bbox(img_width, img_height, bbox):\n",
    "    dw = 1. / img_width\n",
    "    dh = 1. / img_height\n",
    "    x = bbox[0] + bbox[2] / 2.0\n",
    "    y = bbox[1] + bbox[3] / 2.0\n",
    "    w = bbox[2]\n",
    "    h = bbox[3]\n",
    " \n",
    "    x = x * dw\n",
    "    w = w * dw\n",
    "    y = y * dh\n",
    "    h = h * dh\n",
    "    return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3062/3062 [00:02<00:00, 1354.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# 创建文件用于训练数据集的信息\n",
    "# 将COCO格式的标注（bound box）转换为YOLO格式，并生成一个训练数据集的CSV文件\n",
    "f = open('/root/autodl-tmp/kaggle/training/train.csv','w')\n",
    "# 写其文件的表头 id，file_name\n",
    "f.write('id,file_name\\n')\n",
    "\n",
    "# 对 COCO 数据集中的每个图像进行遍历\n",
    "for i in tqdm(range(len(data['images']))):\n",
    "    filename = data['images'][i]['file_name']   # 图像文件名\n",
    "    img_width = data['images'][i]['width']      # 图像宽度\n",
    "    img_height = data['images'][i]['height']\n",
    "    img_id = data['images'][i]['id']\n",
    "    yolo_txt_name = filename.split('.')[0] + '.txt' # 生成YOLO格式的标注文件名，将文件后缀改成\".txt\"\n",
    "    \n",
    "    # 将当前图像的ID和文件名写到 CSV 文件\n",
    "    f.write('{},{}\\n'.format(img_id, filename)) \n",
    "\n",
    "    # 创建用于写到YOLO格式标注的文本\n",
    "    yolo_txt_file = open(os.path.join(yolo_anno_path, yolo_txt_name), 'w')\n",
    "    \n",
    "    # 遍历COCO数据集中的每个标注\n",
    "    for anno in data['annotations']:\n",
    "        # 判断当前标注是否与图像匹配\n",
    "        if anno['image_id'] == img_id:\n",
    "            # 调用函数，将 COCO 格式的边界框转换为 YOLO 格式\n",
    "            yolo_bbox = cc2yolo_bbox(img_width, img_height, anno['bbox']) # \"bbox\": [x,y,width,height]      \n",
    "            # 将 YOLO 格式的标注写到 YOLO 格式标注文件  \n",
    "            yolo_txt_file.write('{} {} {} {} {}\\n'.format(cate_id_map[anno['category_id']], yolo_bbox[0], yolo_bbox[1], yolo_bbox[2], yolo_bbox[3]))\n",
    "    yolo_txt_file.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9860841628484337660</td>\n",
       "      <td>88d8bf3754317ffc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15984033263460081658</td>\n",
       "      <td>ddd2b190ea90dffa.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76077631043502082</td>\n",
       "      <td>010e4833cdb38002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18065680256228130812</td>\n",
       "      <td>fab6307a1a43fffc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9491379842992996352</td>\n",
       "      <td>83b827ae01e68000.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id             file_name\n",
       "0   9860841628484337660  88d8bf3754317ffc.jpg\n",
       "1  15984033263460081658  ddd2b190ea90dffa.jpg\n",
       "2     76077631043502082  010e4833cdb38002.jpg\n",
       "3  18065680256228130812  fab6307a1a43fffc.jpg\n",
       "4   9491379842992996352  83b827ae01e68000.jpg"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看刚生成的训练集\n",
    "train = pd.read_csv('/root/autodl-tmp/kaggle/training/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of total training images: 3062, training images: 2755. validation images: 307\n"
     ]
    }
   ],
   "source": [
    "# 4.将数据划分为训练集和验证集\n",
    "# 将训练数据随机分成两部分:训练集和验证集，通过固定随机种子 random=233 进行划分，10%做验证集\n",
    "train_df, valid_df = train_test_split(train, test_size=0.10, random_state=233)\n",
    "print(f'Size of total training images: {len(train)}, training images: {len(train_df)}. validation images: {len(valid_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>6313228391827179284</td>\n",
       "      <td>579d17c600c50714.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>10846323739029586428</td>\n",
       "      <td>9685e1f96fbec1fc.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>13386314881303920819</td>\n",
       "      <td>b9c5be75f7a540b3.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>6443506009312068821</td>\n",
       "      <td>596bee93892404d5.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>11513085654045198804</td>\n",
       "      <td>9fc6b267460289d4.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>2104996849403692053</td>\n",
       "      <td>1d36737b56060415.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>1494888502052588152</td>\n",
       "      <td>14bee92c1fa90a78.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>1932289094778455674</td>\n",
       "      <td>1ad0deb1a9a1867a.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>12096828553779053656</td>\n",
       "      <td>a7e0917a58cd8458.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>2155400085207516008</td>\n",
       "      <td>1de984f52ba40368.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id             file_name  split\n",
       "1908   6313228391827179284  579d17c600c50714.jpg  train\n",
       "1636  10846323739029586428  9685e1f96fbec1fc.jpg  train\n",
       "361   13386314881303920819  b9c5be75f7a540b3.jpg  train\n",
       "2186   6443506009312068821  596bee93892404d5.jpg  train\n",
       "1393  11513085654045198804  9fc6b267460289d4.jpg  train\n",
       "1314   2104996849403692053  1d36737b56060415.jpg  train\n",
       "753    1494888502052588152  14bee92c1fa90a78.jpg  train\n",
       "1412   1932289094778455674  1ad0deb1a9a1867a.jpg  train\n",
       "767   12096828553779053656  a7e0917a58cd8458.jpg  train\n",
       "634    2155400085207516008  1de984f52ba40368.jpg  train"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用于生成新的数据集并添加 split 列，用于标记每个样本属于训练集还是验证集，通过将训练集和验证集合并生成新的数据集 df\n",
    "train_df.loc[:, 'split'] = 'train'\n",
    "valid_df.loc[:, 'split'] = 'valid'\n",
    "df = pd.concat([train_df, valid_df]).reset_index(drop=True)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为进行 YOLO 自定义训练，准备特定的文件夹结构\n",
    "os.makedirs('../kaggle/training/cowboy/images/train', exist_ok=True)\n",
    "os.makedirs('../kaggle/training/cowboy/images/valid', exist_ok=True)\n",
    "\n",
    "os.makedirs('../kaggle/training/cowboy/labels/train', exist_ok=True)\n",
    "os.makedirs('../kaggle/training/cowboy/labels/valid', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3062/3062 [00:02<00:00, 1376.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# 将图像和标注移动到相关的拆分文件 训练集和验证集\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = df.loc[i]\n",
    "    name = row.file_name.split('.')[0] # 提出 file_name \n",
    "    if row.split == 'train':\n",
    "        copyfile(f'/root/autodl-tmp/data/cowboyoutfits/images/{name}.jpg', f'/root/autodl-tmp/kaggle/training/cowboy/images/train/{name}.jpg')\n",
    "        copyfile(f'/root/autodl-tmp/kaggle/training/yolo_anno/{name}.txt', f'/root/autodl-tmp/kaggle/training/cowboy/labels/train/{name}.txt')\n",
    "    else:\n",
    "        copyfile(f'/root/autodl-tmp/data/cowboyoutfits/images/{name}.jpg', f'/root/autodl-tmp/kaggle/training/cowboy/images/valid/{name}.jpg')\n",
    "        copyfile(f'/root/autodl-tmp/kaggle/training/yolo_anno/{name}.txt', f'/root/autodl-tmp/kaggle/training/cowboy/labels/valid/{name}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.创建数据集配置文件\n",
    "# 数据集配置信息，训练集和验证集的路径，类别数量和类别名称\n",
    "\n",
    "\n",
    "data_yaml = dict(\n",
    "    train = '/root/autodl-tmp/kaggle/training/cowboy/images/train/',\n",
    "    val = '/root/autodl-tmp/kaggle/training/cowboy/images/valid/',\n",
    "    nc = 5,  # 要检测的类别数量为5\n",
    "    names = ['belt', 'sunglasses', 'boot', 'cowboy_hat', 'jacket'] # 类别名称的列表\n",
    ")\n",
    "\n",
    "# we will make the file under the yolov5/data/ directory\n",
    "with open('/root/autodl-tmp/kaggle//training/yolov5/data/data.yaml', 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "# Hyperparameters for COCO training from scratch\n",
    "# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n",
    "# 水平有限，都是默认值\n",
    "\n",
    "\n",
    "lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
    "lrf: 0.2  # final OneCycleLR learning rate (lr0 * lrf)\n",
    "momentum: 0.937  # SGD momentum/Adam beta1\n",
    "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
    "warmup_epochs: 3.0  # warmup epochs (fractions ok)\n",
    "warmup_momentum: 0.8  # warmup initial momentum\n",
    "warmup_bias_lr: 0.1  # warmup initial bias lr\n",
    "box: 0.05  # box loss gain\n",
    "cls: 0.5  # cls loss gain\n",
    "cls_pw: 1.0  # cls BCELoss positive_weight\n",
    "obj: 1.0  # obj loss gain (scale with pixels)\n",
    "obj_pw: 1.0  # obj BCELoss positive_weight\n",
    "iou_t: 0.20  # IoU training threshold\n",
    "anchor_t: 4.0  # anchor-multiple threshold\n",
    "# anchors: 3  # anchors per output layer (0 to ignore)\n",
    "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
    "hsv_h: 0.015  # image HSV-Hue augmentation (fraction\n",
    "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
    "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n",
    "degrees: 0.0  # image rotation (+/- deg)\n",
    "translate: 0.1  # image translation (+/- fraction)\n",
    "scale: 0.5  # image scale (+/- gain)\n",
    "shear: 0.0  # image shear (+/- deg)\n",
    "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
    "flipud: 0.0  # image flip up-down (probability)\n",
    "fliplr: 0.5  # image flip left-right (probability)\n",
    "mosaic: 1.0  # image mosaic (probability)\n",
    "mixup: 0.0  # image mixup (probability)\n",
    "copy_paste: 0.0  # segment copy-paste (probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置训练参数和模型名称的变量\n",
    "\n",
    "BATCH_SIZE = 32     # 批量大小，用于指定每次训练时使用的样本数 \n",
    "EPOCHS = 5          # 训练的轮数，整个数据集被模型处理的次数，每个 epoch 都包含训练和验证过程\n",
    "MODEL = 'yolov5m.pt'  # 模型的名称，即 YOLOv5 预训练权重文件\n",
    "name = f'{MODEL}_BS_{BATCH_SIZE}_EP_{EPOCHS}'   # 用于生成训练的标识名称，即模型名称，批量大小，轮数信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/kaggle/training/yolov5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mboke\u001b[0m (\u001b[33mcompetition_ml\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=images, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/root/autodl-tmp/kaggle/working/kaggle-cowboy, name=yolov5m.pt_BS_32_EP_5, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-203-g0897415 Python-3.10.8 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /root/autodl-tmp/kaggle/working/kaggle-cowboy', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/autodl-tmp/kaggle/training/yolov5/wandb/run-20230804_154511-yahcdzkf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5m.pt_BS_32_EP_5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/competition_ml/kaggle-cowboy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/competition_ml/kaggle-cowboy/runs/yahcdzkf\u001b[0m\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     40410  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20887482 parameters, 20887482 gradients, 48.3 GFLOPs\n",
      "\n",
      "Transferred 475/481 items from yolov5m.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /root/autodl-tmp/kaggle/training/cowboy/labels/train.cache... 27\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.3GB images): 100%|██████████| 2755/2755 [00:04<00:00, 6\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /root/autodl-tmp/kaggle/training/cowboy/labels/valid.cache... 307 \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB images): 100%|██████████| 307/307 [00:01<00:00, 216.3\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.32 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to /root/autodl-tmp/kaggle/working/kaggle-cowboy/yolov5m.pt_BS_32_EP_5/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/root/autodl-tmp/kaggle/working/kaggle-cowboy/yolov5m.pt_BS_32_EP_5\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.67G      0.083    0.03384    0.03257         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        307        600      0.541      0.274      0.156     0.0563\n",
      "Saving model artifact on epoch 1\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      10.4G    0.06033    0.02668    0.01118         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        307        600      0.558      0.424      0.348      0.144\n",
      "Saving model artifact on epoch 2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      4.42G    0.05442     0.0238   0.007145          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        307        600      0.546      0.429      0.354       0.14\n",
      "Saving model artifact on epoch 3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      10.4G    0.04554    0.02243   0.005028         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        307        600      0.748      0.515      0.517      0.261\n",
      "Saving model artifact on epoch 4\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      10.4G    0.04249    0.02196   0.003818         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        307        600      0.727      0.526      0.528      0.277\n",
      "\n",
      "5 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from /root/autodl-tmp/kaggle/working/kaggle-cowboy/yolov5m.pt_BS_32_EP_5/weights/last.pt, 42.2MB\n",
      "Optimizer stripped from /root/autodl-tmp/kaggle/working/kaggle-cowboy/yolov5m.pt_BS_32_EP_5/weights/best.pt, 42.2MB\n",
      "\n",
      "Validating /root/autodl-tmp/kaggle/working/kaggle-cowboy/yolov5m.pt_BS_32_EP_5/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20869098 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        307        600      0.727      0.527      0.528      0.277\n",
      "                  belt        307          1          1          0    0.00137   0.000412\n",
      "            sunglasses        307        268       0.73      0.698      0.705      0.341\n",
      "                  boot        307         56      0.614       0.37      0.427      0.227\n",
      "            cowboy_hat        307         44      0.558      0.818       0.75      0.349\n",
      "                jacket        307        231      0.736      0.749      0.757      0.468\n",
      "Results saved to \u001b[1m/root/autodl-tmp/kaggle/working/kaggle-cowboy/yolov5m.pt_BS_32_EP_5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▅▅███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▄▄▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▂▁█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▅▅███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▅▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss █▃▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss █▃▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▆█▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▁▆█▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.52806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.27731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.72654\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.52579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.52812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.27688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.72748\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.00382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33myolov5m.pt_BS_32_EP_5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/competition_ml/kaggle-cowboy/runs/yahcdzkf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ️⚡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/competition_ml/kaggle-cowboy/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjg3ODQ2MjY2/version_details/v0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 17 media file(s), 7 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230804_154511-yahcdzkf/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n"
     ]
    }
   ],
   "source": [
    "# 8.训练\n",
    "# 在训练过程中，可视化其过程 \n",
    "# 先到 yolov5 文件夹中\n",
    "%cd /root/autodl-tmp/kaggle/training/yolov5\n",
    "\n",
    "# 训练脚本\n",
    "!python train.py --batch {BATCH_SIZE} \\\n",
    "                 --epochs {EPOCHS} \\\n",
    "                 --data data.yaml \\\n",
    "                 --weights {MODEL} \\\n",
    "                 --save-period 1 \\\n",
    "                 --project /root/autodl-tmp/kaggle/working/kaggle-cowboy \\\n",
    "                 --name {name} \\\n",
    "                 --cache images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 W&B 在线展示训练结果，并在本地进行可视化\n",
    "# 将训练结果压缩成ZIP，便于可视化\n",
    "# zip -r /root/autodl-tmp/kaggle/working/output.zip /root/autodl-tmp/kaggle/working/kaggle-cowboy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
